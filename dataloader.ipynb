{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpkf.data_processing import DataProcessor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The elephant sneezed at the sight of potatoes. \",\n",
    "    \"Bats can see via echolocation. See the bat sight sneeze!\",\n",
    "    \"Wondering, she opened the door to the studio.\", \" MOUNTAINS permitors.\"\n",
    "]\n",
    "text = \"\".join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    "from nltk.corpus import gutenberg\n",
    ">>> nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_kwargs = dict(remove_stopwords=True, use_stems=False, \n",
    "                  to_lowercase=True, use_lemma=True, remove_punctuation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.041623592376709\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "w2v = DataProcessor(tokenizer_kwargs=tok_kwargs, vectorizer_kwargs={\"strip_accents\" : \"unicode\"})\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.raw('austen-emma.txt').split(\"\\n\")\n",
    "#emma = [w2v.clean_text(s) for s in emma]\n",
    "\n",
    "#emma = [s for s in emma if len(s) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE False\n",
      "ELEPHANT False\n",
      "SNEEZED False\n",
      "AT False\n",
      "THE False\n",
      "SIGHT False\n",
      "OF False\n",
      "POTATOES False\n",
      ". False\n",
      "BATS False\n",
      "CAN False\n",
      "SEE False\n",
      "VIA False\n",
      "ECHOLOCATION False\n",
      ". False\n",
      "SEE False\n",
      "THE False\n",
      "BAT False\n",
      "SIGHT False\n",
      "SNEEZE False\n",
      "! False\n",
      "WONDERING False\n",
      ", False\n",
      "SHE False\n",
      "OPENED False\n",
      "THE False\n",
      "DOOR False\n",
      "TO False\n",
      "THE False\n",
      "STUDIO False\n",
      ". False\n",
      "$ False\n",
      "MOUNTAINS False\n",
      "PERMITORS False\n",
      ". False\n",
      "ELEPHANT False\n",
      "SNEEZE False\n",
      "SIGHT False\n",
      "POTATO False\n",
      ". False\n",
      "BAT False\n",
      "ECHOLOCATION False\n",
      ". False\n",
      "BAT False\n",
      "SIGHT False\n",
      "SNEEZE False\n",
      "! False\n",
      "WONDER False\n",
      ", False\n",
      "OPEN False\n",
      "DOOR False\n",
      "STUDIO False\n",
      ". False\n",
      "$$ False\n",
      "MOUNTAIN False\n",
      "PERMITOR False\n",
      ". False\n",
      "ELEPHANT False\n",
      "SNEEZE False\n",
      "SIGHT False\n",
      "POTATO False\n",
      ". False\n",
      "BAT False\n",
      "ECHOLOCATION False\n",
      ". False\n",
      "BAT False\n",
      "SIGHT False\n",
      "SNEEZE False\n",
      "! False\n",
      "WONDER False\n",
      ", False\n",
      "OPEN False\n",
      "DOOR False\n",
      "STUDIO False\n",
      ". False\n",
      "$$ False\n",
      "MOUNTAIN False\n",
      "PERMITOR False\n",
      ". False\n"
     ]
    }
   ],
   "source": [
    "clean_corpus =w2v.build_vocabulary(corpus, clean_corpus=True)\n",
    "indexes = w2v.tokens_to_index(w2v.tokenize_corpus(clean_corpus))\n",
    "\n",
    "tokens = w2v.to_ngrams(indexes, 3)\n",
    "dataset = np.array([list(seq) for sentence in tokens for seq in sentence], dtype=np.int64)\n",
    "X, y =  dataset[:, :-1], dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpkf.models.ngram import NgramModel\n",
    "\n",
    "ngram = NgramModel(w2v, 2, load_embedding=True, embedding_dim=300, hidden_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:51<00:00,  4.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 13, 265],\n",
       "        [265, 131],\n",
       "        [131, 449],\n",
       "        ...,\n",
       "        [  8, 380],\n",
       "        [380, 663],\n",
       "        [663, 810]]),\n",
       " array([131, 449,  81, ..., 663, 810, 532]),\n",
       " [25277.56155371666,\n",
       "  22502.80252456665,\n",
       "  21515.356505393982,\n",
       "  21056.035797595978,\n",
       "  20718.793347597122,\n",
       "  20440.897978305817,\n",
       "  20192.052221298218,\n",
       "  19956.855314016342,\n",
       "  19729.494696855545,\n",
       "  19507.583028316498])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram.fit(emma[:], n_epochs=10, clean_corpus=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'her to impose any restraint; and the shadow of authority being'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = emma[25]\n",
    "preds, data = ngram.predict(text, return_dataset=True)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pred(preds, data, text, ngram):\n",
    "    preds = ngram.array_to_words(preds)\n",
    "    data =  ngram.array_to_words(data)\n",
    "    text = \"{}\\n\".format(text)\n",
    "    for d, p in zip(data, preds):\n",
    "        text += \"in: {} | {}\\n\".format(\" \".join(d), p)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her to impose any restraint; and the shadow of authority being\n",
      "in: her to | the\n",
      "in: to impose | ,\n",
      "in: impose any | to\n",
      "in: any restraint | ,\n",
      "in: restraint ; | and\n",
      "in: ; and | the\n",
      "in: and the | the\n",
      "in: the shadow | of\n",
      "in: shadow of | the\n",
      "in: of authority | ,\n",
      "in: authority being | the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_pred(preds, data, text, ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram.dataproc.add_to_vocab(\"pas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The elephant sneezed at the sight of potatoes. ',\n",
       " array(['sight', 'potato', '.', '.'], dtype='<U6'),\n",
       " array([['elephant', 'sneezed'],\n",
       "        ['sneezed', 'sight'],\n",
       "        ['sight', 'potato'],\n",
       "        ['potato', '.']], dtype='<U8'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, dataset = ngram.predict(corpus[0], return_dataset=True)\n",
    "corpus[0], ngram.array_to_words(pred), ngram.array_to_words(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "self = ngram\n",
    "tokens = self.dataproc.clean_text(corpus[0], return_tokens=True)\n",
    "indexes = self.dataproc.tokens_to_index([tokens])\n",
    "ngram_ix = self.dataproc.to_ngrams(indexes, self.context_size)\n",
    "dataset = np.array([list(seq) for sentence in ngram_ix for seq in sentence],\n",
    "                   dtype=np.int64)\n",
    "preds = [self.model(torch.tensor([x], dtype=torch.long)).argmax(1).item() for x in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['elephant', 'sneezed', 'sight'],\n",
       "       ['sneezed', 'sight', 'potato'],\n",
       "       ['sight', 'potato', '.']], dtype='<U8')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['potato', 'bat', 'bat'], dtype='<U6')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elephant': 6,\n",
       " 'sneezed': 14,\n",
       " 'sight': 12,\n",
       " 'potato': 10,\n",
       " '.': 2,\n",
       " 'bat': 3,\n",
       " 'see': 11,\n",
       " 'via': 16,\n",
       " 'echolocation': 5,\n",
       " 'sneeze': 13,\n",
       " '!': 0,\n",
       " 'wondering': 17,\n",
       " ',': 1,\n",
       " 'opened': 8,\n",
       " 'door': 4,\n",
       " 'studio': 15,\n",
       " 'mountain': 7,\n",
       " 'permitors': 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.dataproc.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.nn.NLLLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.ngrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
